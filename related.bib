@INPROCEEDINGS{8192463,
author={N. P. Jouppi and C. Young and N. Patil and D. Patterson and G. Agrawal and R. Bajwa and S. Bates and S. Bhatia and N. Boden and A. Borchers and R. Boyle and P. Cantin and C. Chao and C. Clark and J. Coriell and M. Daley and M. Dau and J. Dean and B. Gelb and T. V. Ghaemmaghami and R. Gottipati and W. Gulland and R. Hagmann and C. R. Ho and D. Hogberg and J. Hu and R. Hundt and D. Hurt and J. Ibarz and A. Jaffey and A. Jaworski and A. Kaplan and H. Khaitan and D. Killebrew and A. Koch and N. Kumar and S. Lacy and J. Laudon and J. Law and D. Le and C. Leary and Z. Liu and K. Lucke and A. Lundin and G. MacKean and A. Maggiore and M. Mahony and K. Miller and R. Nagarajan and R. Narayanaswami and R. Ni and K. Nix and T. Norrie and M. Omernick and N. Penukonda and A. Phelps and J. Ross and M. Ross and A. Salek and E. Samadiani and C. Severn and G. Sizikov and M. Snelham and J. Souter and D. Steinberg and A. Swing and M. Tan and G. Thorson and B. Tian and H. Toma and E. Tuttle and V. Vasudevan and R. Walter and W. Wang and E. Wilcox and D. H. Yoon},
booktitle={2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)},
title={In-datacenter performance analysis of a tensor processing unit},
year={2017},
volume={},
number={},
pages={1-12},
keywords={application specific integrated circuits;circuit optimisation;computer centres;graphics processing units;integrated circuit modelling;low-power electronics;memory architecture;microprocessor chips;neural nets;random-access storage;tensor processing unit;cost-energy-performance;domain-specific hardware;MAC matrix multiply unit;in-datacenter performance analysis;TeraOps/second;software-managed on-chip memory;TPU deterministic execution model;GDDR5 memory;Nvidia K80 GPU;neural networks;TOPS/Watt;production NN applications;server-class Intel Haswell CPU;time-varying optimizations;Transmission line matrix methods;Graphics processing units;Artificial neural networks;Central Processing Unit;Tensile stress;Training;Hardware;DNN;MLP;CNN;RNN;LSTM;neural network;deep learning;domain-specific architecture;accelerator;TensorFlow;TPU;GPU},
doi={10.1145/3079856.3080246},
ISSN={},
month={June},}

@misc{huawei,
  author = {{Huawei Technologies Co., Ltd.}},
  title = {{HUAWEI Reveals the Future of Mobile AI at IFA 2017}},
  year = 2017,
  month = "September",
  howpublished = "\url{https://consumer.huawei.com/en/press/news/2017/ifa2017-kirin970/}",
  note = "[Online; accessed 25 November 2018]",
}

@misc{qualcomm,
  author = {{Qualcomm Technologies, Inc.}},
  title = {{Qualcomm Snapdragon 845 Mobile Platform Powers Superior Connectivity and Immersive Experiences on the Samsung Galaxy Note9}},
  year = 2018,
  month = "August",
  howpublished = "\url{https://www.qualcomm.com/news/releases/2018/08/09/qualcomm-snapdragon-845-mobile-platform-powers-superior-connectivity-and}",
  note = "[Online; accessed 25 November 2018]",
}

@misc{apple,
  author = {{Apple Inc.}},
  title = {{The future is here: iPhone X}},
  year = 2017,
  month = "September",
  howpublished = "\url{https://www.apple.com/newsroom/2017/09/the-future-is-here-iphone-x/}",
  note = "[Online; accessed 25 November 2018]",
}

@misc{techtarget,
  author = {{TechTarget}},
  title = {{Don't get caught up in the neural processing unit hype}},
  year = 2018,
  month = "July",
  howpublished = "\url{https://searchcio.techtarget.com/tip/Dont-get-caught-up-in-the-neural-processing-unit-hype}",
  note = "[Online; accessed 25 November 2018]",
}

@misc{movidius1,
  author = {{Movidius Inc.}},
  title = {{Myriad 2 Vision Processor}},
  year = 2014,
  howpublished = "\url{http://uploads.movidius.com/1441734401-Myriad-2-product-brief.pdf}",
  note = "[Online; accessed 25 November 2018]",
}

@misc{movidius2,
  author = {{Movidius, an Intel Company}},
  title = {{Enhanced Visual Intelligence at the Network Edge}},
  year = 2017,
  howpublished = "\url{https://newsroom.intel.com/wp-content/uploads/sites/11/2017/08/movidius-myriad-xvpu-product-brief.pdf}",
  note = "[Online; accessed 25 November 2018]",
}

@INPROCEEDINGS{1693534,
author={E. Farquhar and C. Gordon and P. Hasler},
booktitle={2006 IEEE International Symposium on Circuits and Systems},
title={A field programmable neural array},
year={2006},
volume={},
number={},
pages={4 pp.-4117},
keywords={analogue circuits;network routing;neural nets;programmable logic arrays;field programmable neural array;analog circuit;biologically relevant circuit components;routing structure;Hardware;Field programmable analog arrays;Field programmable gate arrays;Neurons;Application software;Analog computers;Biology computing;Analog circuits;Routing;Computer networks},
doi={10.1109/ISCAS.2006.1693534},
ISSN={0271-4302},
month={May},}

@INPROCEEDINGS{7818353,
author={M. Wijtvliet and L. Waeijen and H. Corporaal},
booktitle={2016 International Conference on Embedded Computer Systems: Architectures, Modeling and Simulation (SAMOS)},
title={Coarse grained reconfigurable architectures in the past 25 years: Overview and classification},
year={2016},
volume={},
number={},
pages={235-244},
keywords={field programmable gate arrays;reconfigurable architectures;coarse grained reconfigurable architecture;CGRA;field programmable gate array;FPGA;Computer architecture;Field programmable gate arrays;Program processors;Hardware;Dynamic scheduling;Performance evaluation;Logic gates;Coarse Grain Reconfigurable Architecture;CGRA;Classification},
doi={10.1109/SAMOS.2016.7818353},
ISSN={},
month={July},}

@ARTICLE{239745,
author={O. Fujita and Y. Amemiya},
journal={IEEE Transactions on Electron Devices},
title={A floating-gate analog memory device for neural networks},
year={1993},
volume={40},
number={11},
pages={2029-2035},
keywords={analogue storage;CMOS integrated circuits;insulated gate field effect transistors;large scale integration;learning (artificial intelligence);neural chips;high resolution MOSFET current modification;N-well CMOS floating gate process;floating-gate analog memory device;floating-gate MOSFET;neural network LSIs;charge-injection gate;Fowler-Nordheim tunnel junction;charge-storage gate;high voltage control;on-chip learning;Nonvolatile memory;Analog memory;Neural networks;MOSFET circuits;Large scale integration;FETs;Voltage control;Tunneling;Capacitance;Network-on-a-chip},
doi={10.1109/16.239745},
ISSN={0018-9383},
month={Nov},}

@ARTICLE{81862,
author={B. W. Lee and B. J. Sheu and H. Yang},
journal={IEEE Transactions on Circuits and Systems},
title={Analog floating-gate synapses for general-purpose VLSI neural computation},
year={1991},
volume={38},
number={6},
pages={654-658},
keywords={CMOS integrated circuits;neural nets;VLSI;floating-gate-based synapse structure;neural computing;double-polysilicon CMOS process;conductance programmability;charge retention;programmable synapse circuit;neural chip;static-RAM fabrication technologies;Very large scale integration;Analog computers;Neurons;Voltage;Transconductance;Circuits and systems;Multi-layer neural network;Signal processing;Hardware;CMOS process},
doi={10.1109/31.81862},
ISSN={0098-4094},
month={June},}

@misc{machofnewsoul,
  author = {{The Economist Newspaper Limited}},
  title = {{Neuromorphic computing, The machine of a new soul}},
  year = 2013,
  Month = "August",
  howpublished = "\url{https://www.economist.com/science-and-technology/2013/08/03/the-machine-of-a-new-soul}",
  note = "[Online; accessed 2 December 2018]",
}

@misc{emergentkwta,
  author = {{emergent}},
  title = {{CCNBook/Networks/kWTA Equations}},
  year = 2014,
  Month = "August",
  howpublished = "\url{https://grey.colorado.edu/CompCogNeuro/index.php/CCNBook/Networks/kWTA_Equations}",
  note = "[Online; accessed 2 December 2018]",
}

@article{STILLMAKER201774,
title = "Scaling equations for the accurate prediction of CMOS device performance from 180nm to 7nm",
journal = "Integration",
volume = "58",
pages = "74 - 81",
year = "2017",
issn = "0167-9260",
doi = "https://doi.org/10.1016/j.vlsi.2017.02.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167926017300755",
author = "Aaron Stillmaker and Bevan Baas",
keywords = "Transistor scaling, Deep submicron performance, VLSI design, CMOS device",
abstract = "Classical scaling equations which estimate parameters such as circuit delay and energy per operation across technology generations have been extremely useful for predicting performance metrics as well as for comparing designs across fabrication technologies. Unfortunately in the CMOS deep-submicron era, the classical scaling equations are becoming increasingly less accurate and new practical scaling methods are needed. We curve fit second and third-order polynomials to circuit delay, energy, and power dissipation results based on HSpice simulations utilizing the Predictive Technology Model (PTM) and International Technology Roadmap for Semiconductors (ITRS) models. While the classical scaling equations give differences as much as 83Ã—from the predictions of PTM and ITRS models, our predictive polynomial models with table-based coefficients yield a coefficient of determination, or R2, value of greater than 0.95."
}
